{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>3 days 0 hours 9 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Warsaw</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 23 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_sukhwindersingh_lc2wo7</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>219.7 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         3 days 0 hours 9 mins\n",
       "H2O_cluster_timezone:       Europe/Warsaw\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.1\n",
       "H2O_cluster_version_age:    2 months and 23 days\n",
       "H2O_cluster_name:           H2O_from_python_sukhwindersingh_lc2wo7\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    219.7 Mb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.2 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2odeeplearningestimator\n",
    "import h2o\n",
    "import pandas as pd\n",
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "h2o.init()\n",
    "irisData = h2o.import_file(\"/Users/sukhwindersingh/Documents/study/sem2/PDC/iris/iris.data\");\n",
    "votesData = h2o.import_file(\"/Users/sukhwindersingh/Documents/study/sem2/PDC/votes/house-votes-84.data\");\n",
    "sonarData = h2o.import_file(\"/Users/sukhwindersingh/Documents/study/sem2/PDC/sonar/sonar.all-data\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |███████████████████████"
     ]
    }
   ],
   "source": [
    "def calculate_confidenceInterval(ds,confidence):\n",
    "    n = len(ds)\n",
    "    m = np.mean(ds)\n",
    "    std_err = st.sem(ds)\n",
    "    std_dev= np.std(ds)\n",
    "    moe = std_err * st.t.ppf((1 + confidence) / 2., n - 1) #marginOfError\n",
    "    return m,moe;\n",
    "\n",
    "def plotGivenData(m,t,y):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_title(t)\n",
    "    ax1.set_ylabel(y)\n",
    "    ax1.set_xlabel('Method_folds[1]')\n",
    "    ax1.boxplot(m.values(),labels=m.keys())\n",
    "\n",
    "def drawPlot(folds,r_m,r_e,t_m,t_e,label,title):\n",
    "    plt.errorbar(folds,r_m,yerr=r_e,label=\"Rect\",fmt='*',capsize=3,ls='--')\n",
    "    plt.errorbar(folds,t_m,yerr=t_e,label=\"Tanh\",fmt='*',capsize=3,ls='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of folds [1]\")\n",
    "    plt.ylabel(label)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def calculateMPCE(dataSet,predictorColumns,responseColumn,dataSetName):\n",
    "    map_train_error={}\n",
    "    map_test_error={}\n",
    "    map_time={}\n",
    "    activations =[\"rectifier\", \"tanh\"]\n",
    "    folds = [0,5,10]\n",
    "    for activation in activations:    \n",
    "        for fold in folds:\n",
    "            string_model = activation  +\"_\"+  str(fold)\n",
    "            map_train_error[string_model]=[];\n",
    "            map_test_error[string_model]=[];\n",
    "            map_time[string_model]=[];\n",
    "            for i in range(0,10):      \n",
    "                dl = H2ODeepLearningEstimator(hidden=[5,20,100],\n",
    "                                           epochs=100,\n",
    "                                           activation=activation,\n",
    "                                           nfolds=fold)\n",
    "                if fold == 0:\n",
    "                    trainData, testData = dataSet.split_frame(ratios=[.8])\n",
    "                    t0 = time.time()\n",
    "                    dl.train(x=predictorColumns,\n",
    "                              y=responseColumn,\n",
    "                              training_frame=trainData,\n",
    "                              validation_frame=testData)\n",
    "                    t0 = time.time() - t0\n",
    "                    if(dataSetName=='Sonar'):\n",
    "                        map_test_error[string_model].append(dl.mean_per_class_error(valid=True)[0][1])\n",
    "                    else:\n",
    "                        map_test_error[string_model].append(dl.mean_per_class_error(valid=True))\n",
    "                else:\n",
    "                    t0 = time.time()\n",
    "                    dl.train(x=predictorColumns,\n",
    "                         y=responseColumn,\n",
    "                         training_frame=dataSet)\n",
    "                    t0 = time.time() - t0\n",
    "                    if(dataSetName=='Sonar'):\n",
    "                        map_test_error[string_model].append(dl.mean_per_class_error(train=True)[0][1])\n",
    "                    else:    \n",
    "                        map_test_error[string_model].append(dl.mean_per_class_error(xval=True))\n",
    "                if(dataSetName=='Sonar'):\n",
    "                    map_train_error[string_model].append(dl.mean_per_class_error(train=True)[0][1])\n",
    "                else:    \n",
    "                    map_train_error[string_model].append(dl.mean_per_class_error(train=True))\n",
    "                map_time[string_model].append(t0)\n",
    "    rect_test_m = []\n",
    "    rect_test_e = []\n",
    "    tanh_test_m = []\n",
    "    tanh_test_e = []\n",
    "    for k, v in map_test_error.items():\n",
    "        if(k.startswith('r')):\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            rect_test_m.append(m)\n",
    "            rect_test_e.append(i)\n",
    "        else:\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            tanh_test_m.append(m)\n",
    "            tanh_test_e.append(i)\n",
    "    rect_train_m = []\n",
    "    rect_train_e = []\n",
    "    tanh_train_m = []\n",
    "    tanh_train_e = []\n",
    "    for k, v in map_train_error.items():\n",
    "        if(k.startswith('r')):\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            rect_train_m.append(m)\n",
    "            rect_train_e.append(i)\n",
    "        else:\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            tanh_train_m.append(m)\n",
    "            tanh_train_e.append(i)\n",
    "    \n",
    "    rect_time_m = []\n",
    "    rect_time_e = []\n",
    "    tanh_time_m = []\n",
    "    tanh_time_e = []       \n",
    "    for k, v in map_train_error.items():\n",
    "        if(k.startswith('r')):\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            rect_time_m.append(m)\n",
    "            rect_time_e.append(i)\n",
    "        else:\n",
    "            print(k,\" :  \",calculate_confidenceInterval(v,0.95));\n",
    "            m,i=calculate_confidenceInterval(v,0.95)\n",
    "            tanh_time_m.append(m)\n",
    "            tanh_time_e.append(i)\n",
    "    drawPlot(folds,rect_train_m,rect_train_e,tanh_train_m,tanh_train_e,\"MPCE [%]\",'Mean per class error \\n Train results for ' + dataSetName + 'dataset')\n",
    "    drawPlot(folds,rect_test_m,rect_test_e,tanh_test_m,tanh_test_e,\"MPCE [%]\",'Mean per class error \\n Test results for ' + dataSetName + 'dataset')\n",
    "    drawPlot(folds,rect_time_m,rect_time_e,tanh_time_m,tanh_time_e,\"TIME\",'Time results for ' + dataSetName + 'dataset')\n",
    "    \n",
    "    \n",
    "    \n",
    "# calculateMPCE(irisData,irisData.col_names[0:4],irisData.col_names[4],'IRIS')\n",
    "# calculateMPCE(votesData,votesData.col_names[1:16],votesData.columns[0],'Voter')\n",
    "calculateMPCE(sonarData,sonarData.col_names[0:60],sonarData.col_names[60],'Sonar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
